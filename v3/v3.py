# -*- coding: utf-8 -*-
"""v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aUWLxLwY5vYeFKDXqeF7Rmoqx_OoG_PZ
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import os
import cv2

from tensorflow.python.keras import Model
from keras.preprocessing.image import ImageDataGenerator

from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Concatenate, Dropout

from google.colab import drive
drive.mount('/content/drive')

zip_path = "/content/drive/MyDrive/v3/land-ai.zip"
!cp "{zip_path}" .
!unzip -q land-ai.zip
!rm land-ai.zip

main_path = "/content/land-ai/images-o"
image_names = []

for i in os.listdir(main_path):
  image_names.append(os.path.join(main_path,i))
  
image_names.sort()

mask_path = "/content/land-ai/masks-o"
mask_names = []

for i in os.listdir(mask_path):
  mask_names.append(os.path.join(mask_path,i))
  
mask_names.sort()

images=[]

for i in image_names:
  images.append(tf.image.resize(cv2.imread(i,1),(128,128)))

images = np.array(images)

masks=[]

for i in mask_names:
  masks.append(tf.image.resize(cv2.imread(i,1),(128,128)))

masks = np.array(masks)

print(f"masks shape: {masks.shape}")
print(f"images shape: {images.shape}")

masks = masks[:,:,:,:1]

x_train = images[:10000]
x_test = images[10000:]
y_train = masks[:10000]
y_test = masks[10000:]

images = None
masks = None

y_train_1hot = tf.keras.utils.to_categorical(y_train)
y_test_1hot = tf.keras.utils.to_categorical(y_test)

y_train = None
image_names = None
mask_names = None

plt.imshow(x_test[11,:,:,:].astype('uint8'))
plt.show()

plt.imshow(y_test[11,:,:,0].astype('uint8'))
plt.show()

x_in = Input(shape=(128,128, 3))

x_temp = Conv2D(32, (3, 3), activation='relu', padding='same')(x_in)
x_temp = Dropout(0.25)(x_temp)
x_skip1 = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)
x_temp = MaxPooling2D((2,2))(x_skip1)
x_temp = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)
x_temp = Dropout(0.25)(x_temp)
x_skip2 = Conv2D(32, (3, 3), activation='relu', padding='same')(x_temp)
x_temp = MaxPooling2D((2,2))(x_skip2)
x_temp = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)
x_temp = Dropout(0.25)(x_temp)
x_skip3 = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)
x_temp = MaxPooling2D((2,2))(x_skip3)
x_temp = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)
x_temp = Dropout(0.5)(x_temp)
x_temp = Conv2D(64, (3, 3), activation='relu', padding='same')(x_temp)

x_temp = Conv2DTranspose(64, (3, 3), activation='relu',  padding='same')(x_temp)
x_temp = Dropout(0.5)(x_temp)
x_temp = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu',  padding='same')(x_temp)
x_temp = Concatenate()([x_temp, x_skip3])
x_temp = Conv2DTranspose(64, (3, 3), activation='relu',  padding='same')(x_temp)
x_temp = Dropout(0.5)(x_temp)
x_temp = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu',  padding='same')(x_temp)
x_temp = Concatenate()([x_temp, x_skip2])
x_temp = Conv2DTranspose(32, (3, 3), activation='relu',  padding='same')(x_temp)
x_temp = Dropout(0.5)(x_temp)
x_temp = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu',  padding='same')(x_temp)
x_temp = Concatenate()([x_temp, x_skip1])
x_temp = Conv2DTranspose(32, (3, 3), activation='relu',  padding='same')(x_temp)
x_temp = Dropout(0.5)(x_temp)
x_temp = Conv2DTranspose(32, (3, 3), activation='relu',  padding='same')(x_temp)

x_temp = Conv2D(32, (1, 1), activation='relu', padding='same')(x_temp)
x_temp = Conv2D(32, (1, 1), activation='relu', padding='same')(x_temp)
x_out = Conv2D(5, (1, 1), activation='softmax', padding='same')(x_temp)

model = Model(inputs=x_in, outputs=x_out)

model.compile(loss='categorical_crossentropy', optimizer='adam')

history = model.fit(x_train, y_train_1hot, validation_data=(x_test, y_test_1hot), epochs=25, batch_size=64, verbose=0)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

preds = model.predict(x_test)

preds = np.argmax(preds, axis=-1)
print(preds.shape)

plt.imshow(preds[23, :, :])
plt.show()
plt.imshow(y_test[23, :, :, 0])
plt.show()
plt.imshow(x_test[23,:,:,:].astype('uint8'))
plt.show()

plt.imshow(preds[1, :, :])
plt.show()
plt.imshow(y_test[1, :, :, 0])
plt.show()
plt.imshow(x_test[1,:,:,:].astype('uint8'))
plt.show()

for i in range(60):
  plt.imshow(preds[i, :, :])
  plt.show()
  plt.imshow(y_test[i, :, :, 0])
  plt.show()
  plt.imshow(x_test[i,:,:,:].astype('uint8'))
  plt.show()

img = np.array(tf.image.resize(cv2.imread("1.jpg",1),(256,256)))
img = img.reshape(1,*img.shape)
pred = model.predict(img)
pred = np.argmax(pred, axis=-1)

plt.imshow(pred[0, :, :])
plt.show()
plt.imshow(img[0,:,:,:].astype('uint8'))
plt.show()

img = np.array(tf.image.resize(cv2.imread("2.jpg",1),(256,256)))
img = img.reshape(1,*img.shape)
pred = model.predict(img)
pred = np.argmax(pred, axis=-1)

plt.imshow(pred[0, :, :])
plt.show()
plt.imshow(img[0,:,:,:].astype('uint8'))
plt.show()

img = np.array(tf.image.resize(cv2.imread("3.jpg",1),(256,256)))
img = img.reshape(1,*img.shape)
pred = model.predict(img)
pred = np.argmax(pred, axis=-1)

plt.imshow(pred[0, :, :])
plt.show()
plt.imshow(img[0,:,:,:].astype('uint8'))
plt.show()

img = np.array(tf.image.resize(cv2.imread("4.jpg",1),(256,256)))
img = img.reshape(1,*img.shape)
pred = model.predict(img)
pred = np.argmax(pred, axis=-1)

plt.imshow(pred[0, :, :])
plt.show()
plt.imshow(img[0,:,:,:].astype('uint8'))
plt.show()

model.save("sec-version.h5")